{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffdc1cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import default_rng\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bf9cfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b651480e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_covtype\n",
    "X, Y = fetch_covtype(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ef8d0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "Y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "092cfff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "150\n"
     ]
    }
   ],
   "source": [
    "print(len(X[0]))\n",
    "print(len(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65b7f020",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GenerateTrainAndTestDataset(X, Y, test_ratio):\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b41df90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SearchForBestClfUsingRandomCV(X, Y, Classifier_Search):\n",
    "    params = {}\n",
    "    searcher_CV = RandomizedSearchCV(Classifier_Search, scoring='average_precision', cv=10, n_iter=10, param_distributions=params,\n",
    "                            refit=True, n_jobs=-1)\n",
    "    searcher_CV.fit(X, Y)\n",
    "    clf_best = searcher_CV.best_estimator_\n",
    "    \n",
    "    return clf_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b8ebd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TestAccurayOnDataset(X, Y, num_trials, test_size_ratio):\n",
    "    \n",
    "    dict_estimator = {}\n",
    "    dict_estimator['LinearRegression'] = {'train': [], 'test': []}\n",
    "    dict_estimator['SGD'] = {'train': [], 'test': []}\n",
    "    dict_estimator['LogisticRegression'] = {'train': [], 'test': []}\n",
    "    dict_estimator['LinearSVC'] = {'train': [], 'test': []}\n",
    "\n",
    "    dict_estimator['GaussianNB'] = {'train': [], 'test': []}\n",
    "    dict_estimator['AdaBoost'] = {'train': [], 'test': []}\n",
    "    dict_estimator['RandomForest'] = {'train': [], 'test': []}\n",
    "    dict_estimator['GaussianProcess'] = {'train': [], 'test': []}\n",
    "\n",
    "    dict_estimator['NeuralNetwork'] = {'train': [], 'test': []}\n",
    "\n",
    "    \n",
    "    for i_trial in range(0, num_trials):\n",
    "        \n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size_ratio)\n",
    "#         print(i_trial)\n",
    "        \n",
    "        Classifier_LogReg = LogisticRegression(fit_intercept=True)\n",
    "#         clf_LogReg = SearchForBestClfUsingRandomCV(X_train, Y_train, Classifier_LogReg)\n",
    "        clf_LogReg = Classifier_LogReg.fit(X_train, Y_train)\n",
    "        score_LogReg_Train = clf_LogReg.score(X_train, Y_train)\n",
    "        score_LogReg_Test = clf_LogReg.score(X_test, Y_test)\n",
    "        \n",
    "        dict_estimator['LogisticRegression']['train'].append(score_LogReg_Train)\n",
    "        dict_estimator['LogisticRegression']['test'].append(score_LogReg_Test)\n",
    "        \n",
    "#         print(\"LogReg Done\")\n",
    "        \n",
    "        Classifier_RF = RandomForestClassifier()\n",
    "#         clf_RF = SearchForBestClfUsingRandomCV(X_train, Y_train, Classifier_RF)\n",
    "        clf_RF = Classifier_RF.fit(X_train, Y_train)\n",
    "        score_RF_Train = clf_RF.score(X_train, Y_train)\n",
    "        score_RF_Test = clf_RF.score(X_test, Y_test)\n",
    "        \n",
    "        dict_estimator['RandomForest']['train'].append(score_RF_Train)\n",
    "        dict_estimator['RandomForest']['test'].append(score_RF_Test)\n",
    "        \n",
    "        Classifier_NN = MLPClassifier(hidden_layer_sizes=(5,2,2))\n",
    "#        clf_NN = SearchForBestClfUsingRandomCV(X_train, Y_train, Classifier_NN)\n",
    "        clf_NN = Classifier_NN.fit(X_train, Y_train)\n",
    "        score_NN_Train = clf_NN.score(X_train, Y_train)\n",
    "        score_NN_Test = clf_NN.score(X_test, Y_test)\n",
    "        \n",
    "        dict_estimator['NeuralNetwork']['train'].append(score_NN_Train)\n",
    "        dict_estimator['NeuralNetwork']['test'].append(score_NN_Test)\n",
    "        \n",
    "        Classifier_LinearSVC = LinearSVC()\n",
    "#        clf_LinearSVC = SearchForBestClfUsingRandomCV(X_train, Y_train, Classifier_LinearSVC)\n",
    "        clf_LinearSVC = Classifier_LinearSVC.fit(X_train, Y_train)\n",
    "        score_LinearSVC_Train = clf_LinearSVC.score(X_train, Y_train)\n",
    "        score_LinearSVC_Test = clf_LinearSVC.score(X_test, Y_test)\n",
    "        \n",
    "        dict_estimator['LinearSVC']['train'].append(score_LinearSVC_Train)\n",
    "        dict_estimator['LinearSVC']['test'].append(score_LinearSVC_Test)\n",
    "        \n",
    "        Classifier_SGD = SGDClassifier()\n",
    "#        clf_SGD = SearchForBestClfUsingRandomCV(X_train, Y_train, Classifier_SGD)\n",
    "        clf_SGD = Classifier_SGD.fit(X_train, Y_train)\n",
    "        score_SGD_Train = clf_SGD.score(X_train, Y_train)\n",
    "        score_SGD_Test = clf_SGD.score(X_test, Y_test)\n",
    "        \n",
    "        dict_estimator['SGD']['train'].append(score_SGD_Train)\n",
    "        dict_estimator['SGD']['test'].append(score_SGD_Test)\n",
    "        \n",
    "        Classifier_GaussianNB = GaussianNB()\n",
    "#        clf_GaussianNB = SearchForBestClfUsingRandomCV(X_train, Y_train, Classifier_GaussianNB)\n",
    "        clf_GaussianNB = Classifier_GaussianNB.fit(X_train, Y_train)\n",
    "        score_GaussianNB_Train = clf_GaussianNB.score(X_train, Y_train)\n",
    "        score_GaussianNB_Test = clf_GaussianNB.score(X_test, Y_test)\n",
    "        \n",
    "        dict_estimator['GaussianNB']['train'].append(score_GaussianNB_Train)\n",
    "        dict_estimator['GaussianNB']['test'].append(score_GaussianNB_Test)\n",
    "        \n",
    "        Classifier_LinearRegression = LinearRegression()\n",
    "#        clf_LinearRegression = SearchForBestClfUsingRandomCV(X_train, Y_train, Classifier_LinearRegression)\n",
    "        clf_LinearRegression = Classifier_LinearRegression.fit(X_train, Y_train)\n",
    "        score_LinearRegression_Train = clf_LinearRegression.score(X_train, Y_train)\n",
    "        score_LinearRegression_Test = clf_LinearRegression.score(X_test, Y_test)\n",
    "        \n",
    "        dict_estimator['LinearRegression']['train'].append(score_LinearRegression_Train)\n",
    "        dict_estimator['LinearRegression']['test'].append(score_LinearRegression_Test)\n",
    "        \n",
    "        Classifier_AdaBoost = AdaBoostClassifier()\n",
    "#        clf_AdaBoost = SearchForBestClfUsingRandomCV(X_train, Y_train, Classifier_AdaBoost)\n",
    "        clf_AdaBoost = Classifier_AdaBoost.fit(X_train, Y_train)\n",
    "        score_AdaBoost_Train = clf_AdaBoost.score(X_train, Y_train)\n",
    "        score_AdaBoost_Test = clf_AdaBoost.score(X_test, Y_test)\n",
    "        \n",
    "        dict_estimator['AdaBoost']['train'].append(score_AdaBoost_Train)\n",
    "        dict_estimator['AdaBoost']['test'].append(score_AdaBoost_Test)\n",
    "\n",
    "        kernel = 1.0 * RBF(1.0)\n",
    "        Classifier_GP = GaussianProcessClassifier(kernel=kernel,random_state=0)\n",
    "#        clf_GP = SearchForBestClfUsingRandomCV(X_train, Y_train, Classifier_GP)\n",
    "        clf_GP = Classifier_GP.fit(X_train, Y_train)\n",
    "        score_GP_Train = clf_GP.score(X_train, Y_train)\n",
    "        score_GP_Test = clf_GP.score(X_test, Y_test)\n",
    "        \n",
    "        dict_estimator['GaussianProcess']['train'].append(score_GP_Train)\n",
    "        dict_estimator['GaussianProcess']['test'].append(score_GP_Test)\n",
    "\n",
    "#         print(\"RF Done\")\n",
    "#         print(i_trial)\n",
    "        \n",
    "#         score_LinReg = GenerateFaultScore()\n",
    "#         score_SGD = GenerateFaultScore()\n",
    "#         score_LinSVM = GenerateFaultScore()\n",
    "#         score_GNB = GenerateFaultScore()\n",
    "#         score_Ada = GenerateFaultScore()\n",
    "#         score_GP = GenerateFaultScore()\n",
    "#         score_NN = GenerateFaultScore()\n",
    "        \n",
    "#         dict_estimator['LinearRegression'].append(score_LinReg)\n",
    "#         dict_estimator['SGD'].append(score_SGD)\n",
    "#         dict_estimator['LinearSVM'].append(score_LinSVM)\n",
    "#         dict_estimator['GaussianNaiveBayes'].append(score_GNB)\n",
    "#         dict_estimator['AdaBoost'].append(score_Ada)\n",
    "#         dict_estimator['GaussianProcess'].append(score_GP)\n",
    "#         dict_estimator['NeuralNetwork'].append(score_NN)\n",
    "     \n",
    "    return dict_estimator\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "777a9dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PlotResults(list_trials, dict_train, dict_test):\n",
    "    \n",
    "    for key in dict_train.keys():\n",
    "        plt.plot(list_trials, dict_train[key], '--', label=key+\"Train\")\n",
    "        plt.plot(list_trials, dict_test[key], label=key+\"Test\")\n",
    "        \n",
    "    plt.legend(bbox_to_anchor=(1.05, 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "725da8b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0467c590e109494a8bb53d4275e73ebc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'kernel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-3818bcbd9d1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnum_trials\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_trials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m#     print(num_trials)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mdict_estimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTestAccurayOnDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_trials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size_ratio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdict_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-bc09b43dbae1>\u001b[0m in \u001b[0;36mTestAccurayOnDataset\u001b[0;34m(X, Y, num_trials, test_size_ratio)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mdict_estimator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'AdaBoost'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore_AdaBoost_Test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0mClassifier_GP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGaussianProcessClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;31m#        clf_GP = SearchForBestClfUsingRandomCV(X_train, Y_train, Classifier_GP)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mclf_GP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClassifier_GP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'kernel' is not defined"
     ]
    }
   ],
   "source": [
    "# dict_estimator_real = TestAccurayOnDataset(dataset, num_trials)\n",
    "# dict_estimator_k = TestAccurayOnDataset(dataset, num_trials)\n",
    "# dict_estimator_bin = TestAccurayOnDataset(dataset, num_trials)\n",
    "\n",
    "list_trials = np.arange(100,1100,100)\n",
    "\n",
    "list_trials = np.arange(1,5,1)\n",
    "# print(list_trials)\n",
    "\n",
    "test_size_ratio = 0.3333\n",
    "\n",
    "list_keys = ['LogisticRegression', 'RandomForest','NeuralNetwork','LinearSVC','SGD','GaussianNB','LinearRegression','AdaBoost']\n",
    "\n",
    "dict_train_mean = {var: [] for var in list_keys}\n",
    "dict_train_std = {var: [] for var in list_keys}\n",
    "\n",
    "dict_test_mean = {var: [] for var in list_keys}\n",
    "dict_test_std = {var: [] for var in list_keys}\n",
    "\n",
    "for num_trials in tqdm(list_trials):\n",
    "#     print(num_trials)\n",
    "    dict_estimator = TestAccurayOnDataset(X, Y, num_trials, test_size_ratio)\n",
    "    \n",
    "    for key in dict_estimator.keys():\n",
    "        \n",
    "        if(key in dict_train_mean):\n",
    "            dict_train_mean[key].append(np.mean(dict_estimator[key]['train']))\n",
    "            dict_train_std[key].append(np.std(dict_estimator[key]['train']))\n",
    "\n",
    "            dict_test_mean[key].append(np.mean(dict_estimator[key]['test']))\n",
    "            dict_test_std[key].append(np.std(dict_estimator[key]['test']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae4f496",
   "metadata": {},
   "outputs": [],
   "source": [
    "PlotResults(list_trials, dict_train_mean, dict_test_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831e2c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec6ad88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GenerateFaultScore():\n",
    "    s = np.random.normal(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a649b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_list = list(range(100))\n",
    "for x in tqdm(my_list):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b65e1b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c9e097",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
